{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0bb5c39-2fde-4336-8127-8debe7cb2741",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Multi Agent Collaboration - Search Orchestrator Agent\n",
    "\n",
    "Multi-agent collaboration is a sophisticated AI architecture where multiple specialized agents work together in a coordinated manner to solve complex problems that exceed the capabilities of any single agent. In this distributed approach, each agent brings unique expertise and capabilities to the collective system, communicating and sharing information to achieve common goals.\n",
    "\n",
    "In this workshop, we will create a Search Orchestrator agent that will act like a team leader, coordinating with three other specialized agents: \n",
    "1. FAQ Agent: For general questions about policies, procedures, or common inquiries about AnyCompany.\n",
    "1. Product Search Agent: For queries related to finding specific products or product categories.\n",
    "1. Inventory Agent: For questions about stock levels and availability.\n",
    "\n",
    "\n",
    "> ℹ️ In this lab, we are going to run all the Agents in the same runtime. However, in a real life scenario you might run the Agents in different servers and have them communicate via [Streamable HTTP](https://strandsagents.com/latest/user-guide/concepts/tools/mcp-tools/#2-streamable-http).\n",
    "\n",
    "\n",
    "\n",
    "![Orchestrator Agent](orchestrator.png)\n",
    "\n",
    "We are going to reuse the collaborator agents that we created in the previous labs here. Their source code has been included in the current directory as python files.\n",
    "\n",
    "The steps to complete this notebook are:\n",
    "\n",
    "1. Install the necessary packages\n",
    "1. Add environment variables\n",
    "1. Create the collaborator Agents as @tools\n",
    "1. Create the Search Orchestrator Agent\n",
    "1. Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076a5aba-9735-4e98-8a53-0daccd7e94b0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Install the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac05c073-d45b-4d85-9bf8-ae10aa78be8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade -q strands-agents strands-agents-tools boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a483b7",
   "metadata": {},
   "source": [
    "## 2. Environment Configuration\n",
    "The FAQ Agent and Product Search Agent use the [retrieve](https://github.com/strands-agents/tools/blob/main/src/strands_tools/retrieve.py) tool to fetch information from Amazon Bedrock Knowledge Bases. \n",
    "\n",
    "Find the respective Knowledge Base Ids from AWS Console and set in the below variables. Also set the AWS_REGION and MIN_SCORE environment variables needed for the ```retrieve``` tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce3220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Fetch the knowledge base ID of the FAQ Knowledge Base\n",
    "%store -r faq_kb_id\n",
    "print(faq_kb_id)\n",
    "\n",
    "# Fetch the knowledge base ID of the Product Search Knowledge Base from pre-requisites step\n",
    "%store -r product_search_kb_id\n",
    "print(product_search_kb_id)\n",
    "\n",
    "# Also set the AWS REGION and MIN_SCORE needed for the retrieve tool.\n",
    "region = \"us-west-2\"\n",
    "os.environ[\"AWS_REGION\"] = region #Change if needed\n",
    "os.environ[\"MIN_SCORE\"] = \"0.4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e80e55e",
   "metadata": {},
   "source": [
    "## 3. Create the Collaborator Agents\n",
    "\n",
    "We will define 3 collaborator agents as local agents. Their source code, which we saw in the previous labs, have been included as python files in the same directory.\n",
    "\n",
    "Import the strands libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b547d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent, tool\n",
    "from strands_tools import agent_graph\n",
    "from strands.models import BedrockModel\n",
    "from botocore.config import Config as BotocoreConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23daec83",
   "metadata": {},
   "source": [
    "#### Create the BedrockModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5d7363-f715-4849-968b-cd4eb5fae3b0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a boto client config with custom settings\n",
    "boto_config = BotocoreConfig(\n",
    "    retries={\"max_attempts\": 3, \"mode\": \"standard\"},\n",
    "    connect_timeout=5,\n",
    "    read_timeout=60\n",
    ")\n",
    "\n",
    "# Create a Bedrock model instance\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=\"us.amazon.nova-premier-v1:0\",\n",
    "    region_name=region,  # try with different regions than the default - make sure you enable model access in the region you use\n",
    "    temperature=0.3,\n",
    "    top_p=0.8,\n",
    "    boto_client_config=boto_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cb6a27",
   "metadata": {},
   "source": [
    "#### Declare the FAQ Agent as a Strands @tool\n",
    "For this lab, we will be defining the Agents as `@tool`s. The code of `FAQ Agent`, `Product Inventory Agent` and `Product Search Agent` that we saw in the previous labs have been made available locally as \n",
    "1. `FAQAgent.py` \n",
    "1. `InventoryAgent.py` \n",
    "1. `ProductSearchAgent.py` \n",
    "\n",
    "respectively so you can focus on the orchestration part in this lab. \n",
    "\n",
    "All the Agents will be running in the same runtime. However, in a production scenario, each Agent could be running in a different server and communicating with each other using protocols like [A2A](https://a2aprotocol.ai/). \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> ℹ️ ***Tool Best Practices*** - \n",
    "> Language models rely heavily on tool descriptions to determine when and how to use them. Well-crafted descriptions significantly improve tool usage accuracy.\n",
    "> A good tool description should:\n",
    "> 1. Clearly explain the tool's purpose and functionality\n",
    "> 1. Specify when the tool should be used\n",
    "> 1. Detail the parameters it accepts and their formats\n",
    "> 1. Describe the expected output format\n",
    "> 1. Note any limitations or constraints\n",
    "\n",
    "The FAQ Agent @tool simply passes the query to the actual Agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e01511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the FAQAgent from the local python in lab 4. This has the code that we saw in the FAQ Agents lab.\n",
    "from FAQAgent import faq_agent\n",
    "\n",
    "@tool\n",
    "def faq_agent_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Answers questions about AnyCompany.\n",
    "    \n",
    "    Use this tool when you need to find answers to general questions about the\n",
    "    policies, procedures, or common inquiries of AnyCompany.\n",
    "\n",
    "    Args:\n",
    "        query: The search question. (String)\n",
    "    \n",
    "    Returns:\n",
    "        The answer to the question (String)\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Fetching from FAQ Knowledge Base\")\n",
    "    response = faq_agent(f\"Use the knowledge base id {faq_kb_id}. {query}\")\n",
    "    print(f\"The response from FAQ Agent is {response}\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd3dc9",
   "metadata": {},
   "source": [
    "#### Declare the Product Search and Inventory Agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b8686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Product Search and Inventory Agents from local python files.\n",
    "from ProductSearchAgent import product_search_agent\n",
    "from InventoryAgent import inventory_agent\n",
    "\n",
    "\n",
    "@tool\n",
    "def product_search_agent_tool(query: str) -> str:\n",
    "    \"\"\" \n",
    "    Discovers products for customers based on their requirements.\n",
    "\n",
    "    Use this tool when you need to discover some products based\n",
    "    on the requirements of the customer.\n",
    "\n",
    "    This tool uses the Product Search Agent to find products.\n",
    "\n",
    "    Example response:\n",
    "    [\n",
    "     { \"product_id\": \"PROD-010\", \n",
    "       \"product_name\": \"Uniqlo Ultra Light Down Jacket\", \n",
    "       \"brand_name\": \"Uniqlo\", \n",
    "       \"category\": \"Clothing\", \n",
    "       \"subcategory\": \"Outerwear\", \n",
    "       \"gender\": \"Unisex\", \n",
    "       \"price\": 69.90, \n",
    "       \"sale_price\": 49.90, \n",
    "       \"size\": [\"XS\", \"S\", \"M\", \"L\", \"XL\", \"XXL\"], \n",
    "       \"color\": [\"Black\", \"Navy\", \"Red\", \"Olive\", \"Grey\"], \n",
    "       \"materials\": [\"100% Nylon\", \"Down filling\", \"Water-repellent coating\"], \n",
    "       \"season\": \"Fall/Winter\" \n",
    "       },\n",
    "       ...\n",
    "    ]  \n",
    "\n",
    "    Notes:\n",
    "        - This tool only searches the products and does not provide\n",
    "          inventory or availability information\n",
    "\n",
    "    Args:\n",
    "        query: The search requirements from the customer\n",
    "\n",
    "    Returns:\n",
    "        A list of matching product records, each containing:\n",
    "        - id: Unique product identifier (string)\n",
    "        - product_name: Product name\n",
    "        - brand_name: Brand name\n",
    "        - category: Category of the product\n",
    "        - subcategory: Sub category\n",
    "        - gender: Gender that the product applies to\n",
    "        - price: Price\n",
    "        - sale_price: Sales price\n",
    "        - size: Available sizes as an array\n",
    "        - color: Available colors as an array\n",
    "        - materials: Materials\n",
    "        - season: Season\n",
    "    \"\"\"\n",
    "    print(\"Fetching from Product Search Knowledge Base using the query \" + query)\n",
    "\n",
    "    kbRes = product_search_agent(f\"Use the knowledge base id {product_search_kb_id}. {query}\")\n",
    "\n",
    "    print(f\"Products fetched from KB are : {kbRes}\")\n",
    "    return kbRes\n",
    "\n",
    "\n",
    "@tool\n",
    "def inventory_agent_tool(query: str) -> str:\n",
    "    \"\"\" \n",
    "    Checks the inventory of products.\n",
    "\n",
    "    Use this tool if you want to check if a product is in stock or not.\n",
    "\n",
    "    This tool uses the Inventory Agent to find out if the product\n",
    "    is in stock or not.\n",
    "\n",
    "    Example response:\n",
    "        {\n",
    "            \"product_id\" : PRODUCT_ID,\n",
    "            \"in_stock\": IN_STOCK_VALUE\n",
    "        }\n",
    "    \n",
    "    Args:\n",
    "        query: The product Id (String\n",
    "    \n",
    "    Returns:\n",
    "        A JSON containing the fields:\n",
    "        - product_id: Unique product identifier (string)\n",
    "        - in_stock: \"yes\" or \"no\" indicating if the product is in stock or not.\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Fetching from Inventory Agent with the query \" + query)\n",
    "    result = inventory_agent(query)\n",
    "    print(f\"Result from inventory_agent_tool is \\\" {result} \\\"\")\n",
    "    print(\"----------------------------\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6a98b0",
   "metadata": {},
   "source": [
    "## 4. Create the Search Orchestrator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10507f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Orchestrator\n",
    "ORCHESTRATOR_SYSTEM_PROMPT = \"\"\"You are the Search Orchestrator Agent, a sophisticated AI coordinator \n",
    "responsible for managing and directing queries to three specialized collaborator agents: the FAQ Agent, \n",
    "the Product Search Agent, and the Inventory Agent. Your primary role is to efficiently handle user \n",
    "inquiries by determining which agent(s) to engage and in what order.\n",
    "\n",
    "Your key responsibilities include:\n",
    "1. Analyze incoming user queries to understand their intent and requirements.\n",
    "2. Decide which tool(s) to consult based on the nature of the query:\n",
    "   - FAQ Agent Tool: For general questions about policies, procedures, or common inquiries. This tool does \n",
    "                     not have product or product availability related information.\n",
    "   - Product Search Agent Tool: For queries related to finding specific products or product categories.\n",
    "   - Inventory Agent Tool: For questions about stock levels and availability.\n",
    "3. Determine the optimal sequence for consulting these tools if multiple tools are needed.\n",
    "4. Formulate clear, concise sub-queries for each relevant tool.\n",
    "5. Collect and synthesize responses from the collaborator tools.\n",
    "6. Generate a comprehensive, coherent response for the user based on the information gathered.\n",
    "\n",
    "Note:\n",
    "1. Fetch product availability information only when explicitly asked by the customer. \n",
    "2. FAQ Agent Tool does not have product or product availability related information.\n",
    "\n",
    "Remember, your goal is to provide accurate, helpful, and efficient responses to user queries by \n",
    "leveraging the specialized knowledge of each collaborator tool. Always strive for clarity, \n",
    "conciseness, and relevance in your communications with both users and collaborator tools.\n",
    "\"\"\"\n",
    "\n",
    "# Create the orchestrator agent with the collaborator Agents as tools.\n",
    "orchestrator = Agent(\n",
    "    system_prompt=ORCHESTRATOR_SYSTEM_PROMPT,\n",
    "    tools=[faq_agent_tool, product_search_agent_tool, inventory_agent_tool],\n",
    "    model=bedrock_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = orchestrator(\"What is the returns policy of AnyCompany?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df30451",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = orchestrator(\"Product recommendations for clothes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = orchestrator(\"Hello, I am going to attend a cocktail party, and would like some suggestions for smart casual jacket. What can you recommend me? Also check if that's in inventory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1bff21",
   "metadata": {},
   "source": [
    "# End of Workshop\n",
    "Congrats!! You have successfully completed all the labs."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
